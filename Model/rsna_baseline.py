# -*- coding: utf-8 -*-
"""RSNA_baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y4hVLzuUtmhaRDO9tAC_Dj1TRNfED_BM
"""

# Mount to Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Setup exp number
import os

exp_code = 'v2'
exp_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/RSNA/weights', exp_code)

#os.mkdir(exp_dir)

# Authenticate GCP
#from google.colab import auth
#auth.authenticate_user()

#project_id = 'rsna-326901'
#! gcloud config set project {project_id}
#! gsutil ls

# Import data
#bucket_name = 'rsna_preprocessed'
#!gsutil -m cp -r gs://{bucket_name}/ /content/drive/My\ Drive/Data

"""# Prepare dataset"""

# Import packages
import os
import glob
import csv
import sys
import time
from tqdm import tqdm

import math
import random
import numpy as np

import cv2
import PIL
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F

import albumentations

# Load train_labels.csv
csv_path = '/content/drive/MyDrive/Data/rsna_preprocessed/train_labels.csv'

train_labels = pd.read_csv(csv_path)
train_labels

!pip install -q torchio

import torchio as tio
root_dir = '/content/drive/MyDrive/Data/rsna_preprocessed'

# Load train_set and assign input_size
transform = tio.Compose([tio.Resize((64, 64, 64)),
                         tio.transforms.ZNormalization(),])

train_set = tio.datasets.RSNAMICCAI(root_dir, train=True, transform=transform)

subject = train_set[0]
subject.plot()

# Split up train_set to train and val
from torch.utils.data import random_split

# Practice mode
split_ratio = 0.9
n_train_set = int(len(train_set) * split_ratio)
n_val_set = len(train_set) - n_train_set

train_set, val_set = random_split(train_set,
                                  [n_train_set, n_val_set],
                                  generator=torch.Generator().manual_seed(1))

print(len(train_set))
print(len(val_set))

# Generate dataloaders
batch_size = 4

train_loader = torch.utils.data.DataLoader(train_set,
                                           batch_size=batch_size,
                                           shuffle=True)

val_loader = torch.utils.data.DataLoader(val_set,
                                         batch_size=batch_size,
                                         shuffle=False)

print(len(train_loader))
print(len(val_loader))

"""# Import EfficientNet-3D"""

!pip install git+https://github.com/shijianjian/EfficientNet-PyTorch-3D

from efficientnet_pytorch_3d import EfficientNet3D

model = EfficientNet3D.from_name("efficientnet-b0", override_params={'num_classes': 1}, in_channels=1)
model.cuda()

device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'

# Loss function and optimizer
loss_fn = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)

# Import sklearn ROC_AUC score
from sklearn.metrics import roc_auc_score

"""# Training"""

def train(epochs, scan_type, exp_code):

  # Generate lists for tracking training stats
  ls_train_loss = []
  ls_val_loss = []

  # Training
  for epoch_i in range(epochs):
    print('【 Epoch {}/{} 】'.format(epoch_i+1, epochs))
    print(' Training phase...')

    # Reset train_loss
    train_loss = 0
    
    # Set training mode
    model.train()

    for batch in tqdm(train_loader):

      # reset optimizer
      optimizer.zero_grad()

      # Get input array
      input = batch[scan_type]['data'].float().to(device)

      # Feed to the model and get logit
      logits = model(input).squeeze()
      labels = batch['MGMT_value'].float().to(device)
      
      # Loss function
      loss = loss_fn(logits, labels)
      loss.backward()

      # Optimizer
      optimizer.step()

      # Update train loss
      train_loss += loss.item()

    # Train stats of this epoch
    avg_train_loss = train_loss/len(train_loader)
    print('  Avg. train loss: {:.4f}'.format(avg_train_loss))
    print('\n')

    print(' Validation phase...')

    # Reset train_loss
    val_loss = 0
    
    # Set training mode
    model.eval()

    with torch.no_grad():
      for batch in tqdm(val_loader):

        # Get input array
        input = batch[scan_type]['data'].float().to(device)

        # Feed to the model and get logit
        logits = model(input).squeeze()
        labels = batch['MGMT_value'].float().to(device)
      
        # Loss function
        loss = loss_fn(logits, labels)
      
        # Update train loss
        val_loss += loss.item()

      # Train stats of this epoch
      avg_val_loss = val_loss/len(val_loader)
      print('  Avg. val loss: {:.4f}'.format(avg_val_loss))
      print('\n')

    # Recording train stats
    ls_train_loss.append(avg_train_loss)
    ls_val_loss.append(avg_val_loss)

    print(ls_train_loss)
    print(ls_val_loss)
    print('\n')
    
    # Save model if val_loss is less than the previous losses
    if len(ls_val_loss) == 1:
      exp_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/RSNA/weights', exp_code)
      model_name = 'model_' + scan_type
      PATH = os.path.join(exp_dir, model_name) + '.pt'
      torch.save(model.state_dict(), PATH)
      print('  >> Model weights saved.')
      print('\n')

    
    elif avg_val_loss < min(ls_val_loss):
      exp_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/RSNA/weights', exp_code)
      model_name = 'model_' + scan_type
      PATH = os.path.join(exp_dir, model_name) + '.pt'
      torch.save(model.state_dict(), PATH)
      print('  >> Model weights saved.')
      print('\n')

# Train loop
scan_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']

for scan_type in scan_types:
  train(epochs=5, scan_type=scan_type, exp_code=exp_code)